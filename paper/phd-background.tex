\chapter{Background}
\label{chapt:background}

\section{Recurrent Neural Networks}

\subsection{Traditional RNNs}

\subsection{Deep Learning}

LSTM, GRU, qRNN

Neural variants: Hunsburger, nengo\_dl, Maass, Hugh \& Sjenowski

\subsection{Unsupervised Approaches}

SORN, Numenta

\subsection{Reservoir Computing}

LSM, ESN

\subsection{FORCE Learning}

Duggins, Nicola

Aditya & Gerstner, PES

\subsection{Balanced Networks}

Deneve, Memmesheimer, Slotine


\section{Neural Engineering Framework}

\subsection{Principle 1}

\subsection{Principle 2}

\subsection{Principle 3}


\section{Neuromorphic Computing}

Common goals.

\subsection{SpiNNaker}

1 and 2

\subsection{Neurogrid}

\subsection{Braindrop}

\subsection{Loihi}

\subsection{Others}

Spikey, BrainScaleS 1 and 2, Dynapse 1 and 2, TrueNorth, DeepSouth, COLAMN, ODIN, ROOLS, Giacomo and Eliasmith, Tripp, Wang and Tapson, STPU, Neuromemristive random projection networks


\section{Dynamical Systems}

\subsection{Linear Time-Invariant Systems}

State-space representations, transfer functions, filters, convolution, properties, Pade approximants and coordinate transformations

\subsection{Nonlinear Systems}

Linearization, Jacobians, signatures of chaos

