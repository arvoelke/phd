\chapter{Introduction}

Computation cannot exist without time.
Whether we consider the discrete switching of voltage states across transistors in a
digital computer,
or the continuous flow of charges across ion channels within the brain -- 
all physical systems, that we currently know of, make progress on their computations
by changing over time. An overarching focus of this thesis is a computational paradigm
in between these two extremes: neuromorphic hardware.
Here, engineers draw inspiration from how the
brain dynamically integrates information, while leveraging existing knowledge about
how to construct low-power digital and analog circuits.

The emerging field of neuromorphic computing has already
witnessed many successes backed by large companies, small start-ups, and new research
programs being established at various institutions all around the world.
Despite this growing excitement, there exist many challenges when it comes to using
this hardware to perform some desired task.
Generally speaking, neuromorphic programming forces us to rethink our traditional,
\emph{Von Neumann}-like, understanding of computation, and redesign our algorithms to cope with
distributed networks of noisy, heterogeneous, physical units, that locally process their inputs and communicate their outputs via spikes.
Biological nervous systems have already solved these problems, and so we seek to borrow existing
principles and models from neuroscience, exploit their properties using tools from mathematics and engineering,
and use software methods to realize the resulting networks in hardware.
To flip this on its head: we must also be able to look at what some individual piece of hardware can achieve,
and adjust our tools and theory to systematically harness its capabilities.
Analagous to how a single compiler can translate the same C++ code
to dozens of physically distinct digital architectures, we strive to systematically describe
how the same dynamical computations can be mapped onto distinct neuromorphic architectures.

The primary goal of this thesis is to unpack the above statements through the exploration of fundamental problems and their theoretical solutions, validated by practical results that include networks running on the state-of-the-art neuromorphic chips: Braindrop and Loihi.
Our general approach consists of a software stack, and dynamical systems framework,
for specifying computations within a language of low-frequency, low-dimensional, vector spaces.
This approach is also known as the Neural Engineering Framework~(NEF), together with
its software package, Nengo, and related extensions detailed within this thesis.
The ultimate goal of this approach is to develop a unified set of tools for constructing
artificially intelligent agents, that can perform the same kinds of tasks that
humans can perform, while running on neuromorphic hardware consuming far less
power than traditional computers.
Significant progress has been made in this direction over the past two decades, and although we still
have a long ways to go, this thesis aims to highlight a promising path for the neuromorphic community.

When confronted with ambitious goals such as replicating human intelligence, computer scientists will most often point towards
deep learning and its major recent successes such as AlphaGo.
However, the majority of Artificial Neural Networks~(ANNs) in use today, including AlphaGo, are applied to \emph{static} inputs to produce \emph{static} outputs.
For a board game such as Go, this is forgiveable, as the entire state of the game is encapsulated by the current state of the board itself, and so there is technically no need to consider any context nor history in order to optimize across future states.
Practically speaking, there could still be a benefit, for a sub-optimal player, to knowing the history of the game in order to better predict the opponent's strategy.
Nevertheless, this points towards a broader underlying concern: time is not being treated as a fundamental consideration in many of the most successful techniques, which might be limiting their applicability to many real-world problems.
For instance, vision is inherently a continuous-time process, while convolutional ANNs are deployed in visual processing tasks to classify objects in single frames, without internal awareness of how these objects might move or behave.
Specifically, when processing video, frames are often sampled at some arbitrary interval and then processed independently from one another.
Similarly, sequence data is often supplied as a fixed-length vector dependent on some sampling interval.
We will discuss some important exceptions at a later time.
But at large, most ANNs do not begin with {\it time} as a physical aspect intrinsic to the system's input, output, or processing units -- it is usually incorporated later at another level of abstraction.
% This pattern is beginning to reverse, with examples such as deep LSTMs and qRNNs for machine translation and speech synthesis.
% However, we argue that we can do even better, by arming ourselves with tools for better understanding the role of time, and being able to engineer specific dynamic computations into RNNs.

On the other hand, the human brain is a {\it physical system} that must continuously process information over time.
This is crucial for an agent situated in a {\it dynamic} environment wherein all interactions depend on internally and externally evolving states.
The brain naturally learns from and interacts with this environment over many different time-scales. 
From a very young age, children can infer the physics of moving objects, and learn how to interact with them to achieve desired outcomes.
We take much of this for granted, but this means that our brains are constructing explicit and implicit dynamical models of the world, and using these models
to perform behaviourally appriorate computations in real-time.
Consider a real-world example such as driving a car. We must constantly integrate new information with our existing understanding of where we are, where we are headed, and what might happen along the way.
This requires not only an untuitive understanding of the physics of the car, but models of how other drivers behave on the road, with respect to changing traffic lights and road conditions, that play out in parallel while we flexibly plan and coordinate our actions.
Likewise, consider any actively engaging task or hobby that you enjoy. I am willing to bet this activity requires some amount of mentally or physically coordinated interaction with the world, on a similar level of dynamic complexity as in the driving example, such as: playing a video game, participating in a sport, engaging with some form of media, performing music, drawing, or dancing.
Besides such activities being meaningful, fun, and beautiful, they all share the common theme of recruiting a variety of systems in a dynamically coordinated fashion.
% Abstractly, we would like to conceptualize this as a compression hierarchy and decompression hierarchy whose two outside ends are coupled in time. Inside is ones own personal representation of the activity (see Fig. ???). At the core, the system strives to create the stable representation of an `illusion' that all of this takes place at once.
% If one is having fun, then this internal representation will try its best to encompass both ends.

To help appreciate how extraordinary this feat is for the human brain, the mechanisms involved do not have a perfect memory of past inputs.
Each neuron processes information locally by encoding its input current into spike trains.
These action potentials evoke post-synaptic responses that decay exponentially within milliseconds to drive other neurons.
The time-scales over which these mechanisms interface with the world, and interact with each other, determines, and constrains, literally everything that we can do.
The collection of these signal processing units, connected in a particular configuration to form a Spiking Neural Network~(SNN), suffice to perform the computations that we rely upon to function.
This ``signal processing view'' of computation is fundamentally different from conventional views of digital computation.
Time is taken as the starting point for the state of all physical ``devices'' performing the computation (i.e.,~neurons and synapses), and all of the signals being transformed.
This, in turn, brings dynamics front and center, in the explicit use of, and attention to, the system's dynamical state.
% There is no arithmetic logic unit, random-access memory, or instruction set.
As such, there is currently an important divide between the computational approaches taken by the machine learning community and those taken by the brain.
This is not simply a matter of biological detail, but more crucially a matter of thinking of the system that is actually solving these problems as a collection of signal processors.
If our aim is to build artificial systems that are as robust and capable as the human brain, then we should strive to understand computation in such terms.
This means developing a rigorous theoretical understanding of the relationships between the mechanisms of an SNN, its parameters, and some desired computation.

%Another significant motivating factor for this work is the recent surge in neuromorphic computing architectures such as SpiNNaker~\citep{mundy2015efficient}, Neurogrid~\citep{choudhary2012silicon}, Brainstorm~\citep{brainstorm}, and IBM's TrueNorth~\citep{merolla2014million}.
%These platforms are massively-parallel low-power analog and/or digital systems that are designed specifically to simulate large-scale SNNs rivalling the complexity of the human brain.
%Despite the growing excitement surrounding these platforms, the community is struggling to fully unlock the computational power of this hardware.
%We believe this is primarily the result of peoples' inability to reconcile their discrete {\it von Neumann}-like understanding of conventional algorithms with the continuous brain-like processing of neuromorphic hardware.
%To take full advantage of such hardware, our `compilers' must account for the effects of simulated neuron models and synaptic models at the system level, and moreover exploit these effects in useful ways whenever possible.
%This has forced us to come full circle; once again we must understand computation in terms of the brain's processing units.

%The remainder of this thesis will be organized as follows.
%We will first survey existing methods of building RNNs (both spiking and non-spiking) and recent neuromorphic hardware architectures.
%We will then review the main ideas and tools that we use from control theory, linear systems theory, nonlinear dynamics, and systems design.
%Therefore, this thesis will theoretically explore ideas and to solve problems that arise from taking the above view of how the brain processes information. This will be supplemented by numerical simulations which validate theories, specific examples which demonstrate applicability, and connections to experimental studies which support or constrain our models when appropriate.
%Many of these problems are driven by current unpublished challenges within the neuromorphic community.
%A secondary goal is to demonstrate that these methods are practically useful by surpassing state-of-the-art results in machine learning, although we will not consider it a failure if this is not achieved within the remaining time span of the thesis, since there is still much ground to cover in theoretical foundations.
%Overall we aim to reveal new insights and make new methods widely available, that we hope will prove useful to engineers, theorists, and practitioners alike.

